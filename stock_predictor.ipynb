{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset , TensorDataset\n",
    "from utilities import *\n",
    "from model import *\n",
    "import fds\n",
    "import os\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fds.list_status('2016-01-01', '2019-12-31', columns=None)\n",
    "bars = fds.bar('2016-01-01','2019-12-31', freq='1d')\n",
    "# 涨跌停筛选 截面日超过一定时间比例则删 flag为1 \n",
    "threshold_of_grow_and_decline = 0.5\n",
    "flager = fds.bar('2016-01-01','2019-12-31', freq='5m')\n",
    "high_max = flager.groupby(['date', 'symbol'])['high'].transform('max')\n",
    "low_min = flager.groupby(['date', 'symbol'])['low'].transform('min')\n",
    "flager['close_ge_high'] = (flager['close'] >= high_max).astype(int )\n",
    "flager['close_le_low'] = (flager['close'] <= low_min).astype(int)\n",
    "flags_high_ratio = flager.groupby(['date', 'symbol'])['close_ge_high'].transform('mean')\n",
    "flags_low_ratio = flager.groupby(['date', 'symbol'])['close_le_low'].transform('mean')\n",
    "flager['flag'] = ((flags_high_ratio > threshold_of_grow_and_decline) | (flags_low_ratio > threshold_of_grow_and_decline)).astype(int)\n",
    "daily_flags = (flager.groupby(['date', 'symbol'])['flag']\n",
    "               .first()\n",
    "               .reset_index())\n",
    "pools = {}\n",
    "# PT当日无分钟频数据（PT）上市日期小于等于10 每日成交比最少的4%股票PT大概在4.5% 最终删除率在10%左右\n",
    "merged = pd.merge(bars, daily_flags, on=['date', 'symbol'], how='left')\n",
    "merged['flag'] = merged['flag'].fillna(1)\n",
    "merged = pd.merge(merged, status, on=['date', 'symbol'], how='left')\n",
    "merged[['ST','PT']] = merged[['ST','PT']].fillna(0)\n",
    "merged['listed_days'] = merged['listed_days'].fillna(1)\n",
    "merged['flag'] = merged['flag'].astype(int) | (merged['listed_days'] <= 10).astype(int)\n",
    "merged['rank'] = merged.groupby('date')['match_items'].rank(pct=True)\n",
    "merged.loc[merged['rank'] <= 0.05, 'flag'] = 1\n",
    "\n",
    "# 股票池\n",
    "filtered = merged[(merged['flag'] != 1)]\n",
    "pools = {date: symbols.reset_index(drop=True) for date, symbols in filtered.groupby('date')['symbol']}\n",
    "pools_df = pd.concat(pools.values(), keys=pools.keys()).reset_index().drop('level_1', axis=1)\n",
    "pools_df.columns = ['date', 'symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>600005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979156</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979157</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979158</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979159</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979160</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2979161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  symbol\n",
       "0       2016-01-04  600000\n",
       "1       2016-01-04  600004\n",
       "2       2016-01-04  600005\n",
       "3       2016-01-04  600006\n",
       "4       2016-01-04  600007\n",
       "...            ...     ...\n",
       "2979156 2019-12-31  300800\n",
       "2979157 2019-12-31  300802\n",
       "2979158 2019-12-31  300803\n",
       "2979159 2019-12-31  300805\n",
       "2979160 2019-12-31  300806\n",
       "\n",
       "[2979161 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       600000\n",
       "1       600004\n",
       "2       600005\n",
       "3       600006\n",
       "4       600007\n",
       "         ...  \n",
       "2366    300485\n",
       "2367    300487\n",
       "2368    300488\n",
       "2369    300489\n",
       "2370    300498\n",
       "Name: symbol, Length: 2371, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools[pd.Timestamp('2016-01-04')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alpha088_to_df(df):\n",
    "    # (CLOSE-DELAY(CLOSE,20))/DELAY(CLOSE,20)*100\n",
    "    def calculate(group):\n",
    "        group['alpha88'] = (group['close']/group['close'].shift(20)-1)*100\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha084_to_df(df):\n",
    "    # SUM((CLOSE>DELAY(CLOSE,1)?VOLUME:(CLOSE<DELAY(CLOSE,1)?-VOLUME:0)),20)\n",
    "    def calculate(group):\n",
    "        group['alpha84'] = np.where(group['close'].diff(1)>0,group['volume'],np.where(group['close'].diff(1)==0,0,-group['volume']))\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def Alpha080_to_df(df):\n",
    "    # (VOLUME-DELAY(VOLUME,5))/DELAY(VOLUME,5)*100\n",
    "    def calculate(group):\n",
    "        group['alpha80'] = (group['volume'] / group['volume'].shift(5) -1) *100\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha071_to_df(df):\n",
    "    # (CLOSE-MEAN(CLOSE,24))/MEAN(CLOSE,24)*100\n",
    "    def calculate(group):\n",
    "        group['alpha71'] = (group['close']/group['close'].rolling(window=24,min_periods=24).mean() -1)*100\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha070_to_df(df):\n",
    "    # STD(AMOUNT,6)\n",
    "    def calculate(group):\n",
    "        group['alpha70'] = group['turnover'].rolling(window=6).std()\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha069_to_df(df):\n",
    "    # (SUM(DTM,20)>SUM(DBM,20)？(SUM(DTM,20)-SUM(DBM,20))/SUM(DTM,20)：(SUM(DTM,20)=SUM(DBM,20)？0：(SUM(DTM,20)-SUM(DBM,20))/SUM(DBM,20)))\n",
    "    # DTM = (OPEN<=DELAY(OPEN,1)?0:MAX((HIGH-OPEN),(OPEN-DELAY(OPEN,1))))\n",
    "    # DBM = (OPEN>=DELAY(OPEN,1)?0:MAX((OPEN-LOW),(OPEN-DELAY(OPEN,1))))\n",
    "    def calculate(group):\n",
    "        group['DTM'] = np.where(group['open']<=group['open'].shift(1) , 0 , np.maximum(group['high']-group['open'] , group['open']-group['open'].shift(1)))\n",
    "        group['DBM'] = np.where(group['open']>=group['open'].shift(1) , 0 , np.maximum(group['open']-group['low'] , group['open']-group['open'].shift(1)))\n",
    "        condition1 = group['DTM'].rolling(window = 20).sum() > group['DBM'].rolling(window = 20).sum()\n",
    "        condition2 = group['DTM'].rolling(window = 20).sum() < group['DBM'].rolling(window = 20).sum()\n",
    "        group['alpha69'] = 0\n",
    "        group['alpha69'][condition1] = (1 - group['DBM'].rolling(window = 20).sum() / group['DTM'].rolling(window = 20).sum())[condition1]\n",
    "        group['alpha69'][condition2] = (group['DTM'].rolling(window = 20).sum() / group['DBM'].rolling(window = 20).sum() - 1)[condition2]\n",
    "        columns = group.columns.difference(['DTM', 'DBM'])\n",
    "        return group[columns]\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha060_to_df(df):\n",
    "    # SUM(((CLOSE-LOW)-(HIGH-CLOSE))./(HIGH-LOW).*VOLUME,20)\n",
    "    def calculate(group):\n",
    "        group['alpha60'] = ((2*group['close']-group['low']-group['high'])/(group['high']-group['low'])*group['volume']).rolling(window=20).sum()\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha059_to_df(df):\n",
    "    # SUM((CLOSE=DELAY(CLOSE,1)?0:CLOSE-(CLOSE>DELAY(CLOSE,1)?MIN(LOW,DELAY(CLOSE,1)):MAX(HIGH,DELAY(CLOSE,1)))),20)\n",
    "    def calculate(group):\n",
    "        group['alpha59'] = 0\n",
    "        condition1 = (group['close'].diff(1)>0)\n",
    "        condition2 = (group['close'].diff(1)<0)\n",
    "        \n",
    "        group['alpha59'][condition1] = group['close'][condition1] - np.minimum(group['low'][condition1], group['close'].shift(1)[condition1])\n",
    "        group['alpha59'][condition2] = group['close'][condition2] - np.maximum(group['high'][condition2], group['close'].shift(1)[condition2])\n",
    "        group['alpha59'] = group['alpha59'].rolling(window = 20, min_periods=20).sum()\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate) \n",
    "    return df.reset_index(drop=True)\n",
    "    \n",
    "def Alpha046_to_df(df):\n",
    "    # (MEAN(CLOSE,3)+MEAN(CLOSE,6)+MEAN(CLOSE,12)+MEAN(CLOSE,24))/(4*CLOSE)\n",
    "    def calculate(group):\n",
    "        group['alpha46'] = (group['close'].rolling(window=3).mean() + group['close'].rolling(window=6).mean() + group['close'].rolling(window=12).mean() + group['close'].rolling(window=24).mean()) /(4*group['close'])\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha040_to_df(df):\n",
    "    # SUM((CLOSE>DELAY(CLOSE,1)?VOLUME:0),26)/SUM((CLOSE<=DELAY(CLOSE,1)?VOLUME:0),26)*100\n",
    "    def calculate(group):\n",
    "        group['delay_close'] = group['close'].shift(1)\n",
    "        group['alpha1'] = np.where(group['delay_close'] < group['close'], group['volume'], 0)\n",
    "        group['alpha2'] = np.where(group['delay_close'] >= group['close'], group['volume'], 0)\n",
    "        group['alpha40'] = group['alpha1'].rolling(window = 26,).sum() / group['alpha2'].rolling(window = 26,).sum() * 100\n",
    "        columns = group.columns.difference(['delay_close', 'alpha1' , 'alpha2'])\n",
    "        return group[columns]\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha031_to_df(df):\n",
    "    # (CLOSE-MEAN(CLOSE,12))/MEAN(CLOSE,12)*100\n",
    "    def calculate(group):\n",
    "        group['average'] = group['close'].rolling(window = 12, min_periods=12).mean() \n",
    "        group['alpha31'] = (group['close']-group['average'])/group['average'] * 100\n",
    "        columns = group.columns.difference(['average'])\n",
    "        return group[columns]\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha029_to_df(df):\n",
    "    # (CLOSE-DELAY(CLOSE,6))/DELAY(CLOSE,6)*VOLUME\n",
    "    def calculate(group):\n",
    "        group['alpha29'] = (group['close']-group['close'].shift(window))/group['close'].shift(window)*group['volume']\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha027_to_df(df):\n",
    "    # WMA((CLOSE-DELAY(CLOSE,3))/DELAY(CLOSE,3)*100+(CLOSE-DELAY(CLOSE,6))/DELAY(CLOSE,6)*100,12)\n",
    "    def calculate(group):\n",
    "        group['ret'] = (group['close']-group['close'].shift(3))/group['close'].shift(3) * 100 + (group['close']-group['close'].shift(6))/group['close'].shift(6) * 100\n",
    "        weights = np.array([0.9**i for i in range(12)])[::-1]\n",
    "        group['alpha27'] = group['ret'].rolling(window=12 , min_periods=12).apply(lambda x: np.dot(x,weights) / weights.sum())\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha026_to_df(df):\n",
    "    # ((((SUM(CLOSE, 7) / 7) - CLOSE)) + ((CORR(VWAP, DELAY(CLOSE, 5), 230))))\n",
    "\n",
    "    df['vwap'] = df['turnover'] / df['volume']\n",
    "    \n",
    "    def calculate(group):\n",
    "        group['avg_close_7'] = group['close'].rolling(window=7, min_periods=1).mean()\n",
    "        group['close_diff'] = group['avg_close_7'] - group['close']\n",
    "        group['corr_vwap_close'] = group['vwap'].rolling(window=230, min_periods=1).corr(group['close'].shift(5))\n",
    "        group['alpha26'] = group['close_diff'] + group['corr_vwap_close']\n",
    "        columns = group.columns.difference(['avg_close_7', 'close_diff' , 'corr_vwap_close'])\n",
    "        return group[columns]\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def Alpha011_to_df(df):\n",
    "    # SUM(((CLOSE-LOW)-(HIGH-CLOSE))./(HIGH-LOW).*VOLUME,6)\n",
    "    df['alpha11'] = (2*df['close']-df['low']-df['high'])/(df['high']-df['low'])*df['volume']\n",
    "    def calculate(group):\n",
    "        group['alpha11'] = group['alpha11'].rolling(window=6 , min_periods=6).sum()\n",
    "        return group\n",
    "    df = df.groupby('symbol').apply(calculate)\n",
    "    return df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Alpha088_to_df(df)\n",
    "df = Alpha084_to_df(df)\n",
    "df = Alpha080_to_df(df)\n",
    "df = Alpha071_to_df(df)\n",
    "df = Alpha070_to_df(df)\n",
    "df = Alpha069_to_df(df)\n",
    "df = Alpha060_to_df(df)\n",
    "df = Alpha059_to_df(df)\n",
    "df = Alpha046_to_df(df)\n",
    "df = Alpha040_to_df(df)\n",
    "df = Alpha031_to_df(df)\n",
    "df = Alpha029_to_df(df)\n",
    "df = Alpha027_to_df(df)\n",
    "df = Alpha026_to_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Alpha088_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symbol\n",
       "000001    975\n",
       "000002    975\n",
       "000004    975\n",
       "000005    975\n",
       "000006    975\n",
       "         ... \n",
       "688368     57\n",
       "688369     44\n",
       "688388    111\n",
       "688389     41\n",
       "688399     19\n",
       "Length: 3784, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('symbol').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>match_items</th>\n",
       "      <th>alpha88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000001</td>\n",
       "      <td>11.99</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>11.23</td>\n",
       "      <td>11.33</td>\n",
       "      <td>56349787</td>\n",
       "      <td>6.603762e+08</td>\n",
       "      <td>24835</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>000001</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.27</td>\n",
       "      <td>11.57</td>\n",
       "      <td>11.15</td>\n",
       "      <td>11.40</td>\n",
       "      <td>66326995</td>\n",
       "      <td>7.555314e+08</td>\n",
       "      <td>29217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>000001</td>\n",
       "      <td>11.40</td>\n",
       "      <td>11.42</td>\n",
       "      <td>11.56</td>\n",
       "      <td>11.39</td>\n",
       "      <td>11.53</td>\n",
       "      <td>51570644</td>\n",
       "      <td>5.916985e+08</td>\n",
       "      <td>20359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>000001</td>\n",
       "      <td>11.53</td>\n",
       "      <td>11.41</td>\n",
       "      <td>11.41</td>\n",
       "      <td>10.91</td>\n",
       "      <td>10.94</td>\n",
       "      <td>17476110</td>\n",
       "      <td>1.948695e+08</td>\n",
       "      <td>6596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>000001</td>\n",
       "      <td>10.94</td>\n",
       "      <td>11.21</td>\n",
       "      <td>11.29</td>\n",
       "      <td>10.90</td>\n",
       "      <td>11.12</td>\n",
       "      <td>74752758</td>\n",
       "      <td>8.313345e+08</td>\n",
       "      <td>29002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>000001</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.56</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.30</td>\n",
       "      <td>41491798</td>\n",
       "      <td>6.796646e+08</td>\n",
       "      <td>31607</td>\n",
       "      <td>5.365223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>000001</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.34</td>\n",
       "      <td>16.48</td>\n",
       "      <td>16.32</td>\n",
       "      <td>16.47</td>\n",
       "      <td>37203386</td>\n",
       "      <td>6.103818e+08</td>\n",
       "      <td>22331</td>\n",
       "      <td>6.326662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>000001</td>\n",
       "      <td>16.47</td>\n",
       "      <td>16.53</td>\n",
       "      <td>16.93</td>\n",
       "      <td>16.43</td>\n",
       "      <td>16.63</td>\n",
       "      <td>104257472</td>\n",
       "      <td>1.741473e+09</td>\n",
       "      <td>54738</td>\n",
       "      <td>8.763898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>000001</td>\n",
       "      <td>16.63</td>\n",
       "      <td>16.46</td>\n",
       "      <td>16.63</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.57</td>\n",
       "      <td>97697031</td>\n",
       "      <td>1.603153e+09</td>\n",
       "      <td>50806</td>\n",
       "      <td>7.877604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>000001</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.63</td>\n",
       "      <td>16.31</td>\n",
       "      <td>16.45</td>\n",
       "      <td>70444225</td>\n",
       "      <td>1.154704e+09</td>\n",
       "      <td>40738</td>\n",
       "      <td>6.472492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>975 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  symbol  pre_close   open   high    low  close     volume  \\\n",
       "0   2016-01-04  000001      11.99  12.00  12.03  11.23  11.33   56349787   \n",
       "1   2016-01-05  000001      11.33  11.27  11.57  11.15  11.40   66326995   \n",
       "2   2016-01-06  000001      11.40  11.42  11.56  11.39  11.53   51570644   \n",
       "3   2016-01-07  000001      11.53  11.41  11.41  10.91  10.94   17476110   \n",
       "4   2016-01-08  000001      10.94  11.21  11.29  10.90  11.12   74752758   \n",
       "..         ...     ...        ...    ...    ...    ...    ...        ...   \n",
       "970 2019-12-25  000001      16.40  16.45  16.56  16.24  16.30   41491798   \n",
       "971 2019-12-26  000001      16.30  16.34  16.48  16.32  16.47   37203386   \n",
       "972 2019-12-27  000001      16.47  16.53  16.93  16.43  16.63  104257472   \n",
       "973 2019-12-30  000001      16.63  16.46  16.63  16.10  16.57   97697031   \n",
       "974 2019-12-31  000001      16.57  16.57  16.63  16.31  16.45   70444225   \n",
       "\n",
       "         turnover  match_items   alpha88  \n",
       "0    6.603762e+08        24835       NaN  \n",
       "1    7.555314e+08        29217       NaN  \n",
       "2    5.916985e+08        20359       NaN  \n",
       "3    1.948695e+08         6596       NaN  \n",
       "4    8.313345e+08        29002       NaN  \n",
       "..            ...          ...       ...  \n",
       "970  6.796646e+08        31607  5.365223  \n",
       "971  6.103818e+08        22331  6.326662  \n",
       "972  1.741473e+09        54738  8.763898  \n",
       "973  1.603153e+09        50806  7.877604  \n",
       "974  1.154704e+09        40738  6.472492  \n",
       "\n",
       "[975 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['symbol']=='000001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = '2016-01-03'\n",
    "end_date = '2019-12-31'\n",
    "prediction_size = 3\n",
    "day_count = len(fds.range_trading_days(begin_date, end_date, dtype=None))\n",
    "df = bars\n",
    "df['ret'] = df['close']/df['pre_close']-1\n",
    "df['ret_predict'] = df.groupby('symbol')['ret'].transform(\n",
    "    lambda x: x.rolling(window=prediction_size).apply(lambda y: (y + 1).prod(), raw=True) - 1\n",
    ")\n",
    "df = df.dropna()\n",
    "filtered_df = pd.merge(df, pools_df, on=['date', 'symbol'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bars.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>match_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>688005</td>\n",
       "      <td>30.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  symbol  pre_close  open  high  low  close  volume  turnover  \\\n",
       "1491 2019-11-06  688005      30.93   NaN   NaN  NaN  30.93       0       0.0   \n",
       "\n",
       "      match_items  \n",
       "1491            0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools_df[pools_df.isna().any(axis=1)] # 值有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = filtered_df.columns.difference(['date', 'symbol'])\n",
    "standardized_df = filtered_df.copy()  \n",
    "standardized_df[columns] = (\n",
    "    filtered_df[columns]\n",
    "    .groupby(filtered_df['date'])\n",
    "    .transform(lambda x: (x - x.mean()) / x.std())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>match_items</th>\n",
       "      <th>ret</th>\n",
       "      <th>ret_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>600000</td>\n",
       "      <td>-0.220698</td>\n",
       "      <td>-0.229221</td>\n",
       "      <td>-0.248218</td>\n",
       "      <td>-0.220417</td>\n",
       "      <td>-0.241471</td>\n",
       "      <td>0.785581</td>\n",
       "      <td>1.728766</td>\n",
       "      <td>0.674041</td>\n",
       "      <td>-1.017238</td>\n",
       "      <td>1.323708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>600004</td>\n",
       "      <td>-0.480222</td>\n",
       "      <td>-0.482740</td>\n",
       "      <td>-0.490082</td>\n",
       "      <td>-0.476231</td>\n",
       "      <td>-0.485146</td>\n",
       "      <td>-0.266007</td>\n",
       "      <td>-0.445720</td>\n",
       "      <td>-0.380980</td>\n",
       "      <td>-0.383024</td>\n",
       "      <td>0.502618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>600005</td>\n",
       "      <td>-1.008425</td>\n",
       "      <td>-1.010144</td>\n",
       "      <td>-0.994956</td>\n",
       "      <td>-1.015485</td>\n",
       "      <td>-0.994934</td>\n",
       "      <td>5.315688</td>\n",
       "      <td>1.425623</td>\n",
       "      <td>1.929654</td>\n",
       "      <td>3.039265</td>\n",
       "      <td>2.444876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>600006</td>\n",
       "      <td>-0.773668</td>\n",
       "      <td>-0.775920</td>\n",
       "      <td>-0.772172</td>\n",
       "      <td>-0.772379</td>\n",
       "      <td>-0.774739</td>\n",
       "      <td>0.250161</td>\n",
       "      <td>-0.167058</td>\n",
       "      <td>0.402586</td>\n",
       "      <td>-0.265849</td>\n",
       "      <td>-0.449312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>600007</td>\n",
       "      <td>-0.278310</td>\n",
       "      <td>-0.282819</td>\n",
       "      <td>-0.300304</td>\n",
       "      <td>-0.281747</td>\n",
       "      <td>-0.296259</td>\n",
       "      <td>-0.354131</td>\n",
       "      <td>-0.497826</td>\n",
       "      <td>-0.629813</td>\n",
       "      <td>-0.942688</td>\n",
       "      <td>-0.125699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733388</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300805</td>\n",
       "      <td>0.212108</td>\n",
       "      <td>0.190558</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.199365</td>\n",
       "      <td>0.287583</td>\n",
       "      <td>0.303709</td>\n",
       "      <td>1.265191</td>\n",
       "      <td>1.891532</td>\n",
       "      <td>5.087656</td>\n",
       "      <td>2.890119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733389</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300806</td>\n",
       "      <td>0.684986</td>\n",
       "      <td>0.686352</td>\n",
       "      <td>0.716239</td>\n",
       "      <td>0.695415</td>\n",
       "      <td>0.689041</td>\n",
       "      <td>-0.379467</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.058665</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>-1.801336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733390</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300808</td>\n",
       "      <td>0.197558</td>\n",
       "      <td>0.201329</td>\n",
       "      <td>0.193641</td>\n",
       "      <td>0.206410</td>\n",
       "      <td>0.194404</td>\n",
       "      <td>-0.406718</td>\n",
       "      <td>-0.253716</td>\n",
       "      <td>-0.259289</td>\n",
       "      <td>-0.266124</td>\n",
       "      <td>-2.689775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733391</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300809</td>\n",
       "      <td>0.275369</td>\n",
       "      <td>0.277995</td>\n",
       "      <td>0.276107</td>\n",
       "      <td>0.286790</td>\n",
       "      <td>0.278423</td>\n",
       "      <td>-0.430935</td>\n",
       "      <td>-0.279941</td>\n",
       "      <td>-0.377621</td>\n",
       "      <td>0.131903</td>\n",
       "      <td>-1.265594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733392</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>300810</td>\n",
       "      <td>1.773078</td>\n",
       "      <td>1.761894</td>\n",
       "      <td>1.787673</td>\n",
       "      <td>1.756685</td>\n",
       "      <td>1.728853</td>\n",
       "      <td>-0.395777</td>\n",
       "      <td>0.318454</td>\n",
       "      <td>0.397276</td>\n",
       "      <td>-1.152539</td>\n",
       "      <td>-3.110605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2733393 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  symbol  pre_close      open      high       low     close  \\\n",
       "0       2016-01-06  600000  -0.220698 -0.229221 -0.248218 -0.220417 -0.241471   \n",
       "1       2016-01-06  600004  -0.480222 -0.482740 -0.490082 -0.476231 -0.485146   \n",
       "2       2016-01-06  600005  -1.008425 -1.010144 -0.994956 -1.015485 -0.994934   \n",
       "3       2016-01-06  600006  -0.773668 -0.775920 -0.772172 -0.772379 -0.774739   \n",
       "4       2016-01-06  600007  -0.278310 -0.282819 -0.300304 -0.281747 -0.296259   \n",
       "...            ...     ...        ...       ...       ...       ...       ...   \n",
       "2733388 2019-12-31  300805   0.212108  0.190558  0.276420  0.199365  0.287583   \n",
       "2733389 2019-12-31  300806   0.684986  0.686352  0.716239  0.695415  0.689041   \n",
       "2733390 2019-12-31  300808   0.197558  0.201329  0.193641  0.206410  0.194404   \n",
       "2733391 2019-12-31  300809   0.275369  0.277995  0.276107  0.286790  0.278423   \n",
       "2733392 2019-12-31  300810   1.773078  1.761894  1.787673  1.756685  1.728853   \n",
       "\n",
       "           volume  turnover  match_items       ret  ret_predict  \n",
       "0        0.785581  1.728766     0.674041 -1.017238     1.323708  \n",
       "1       -0.266007 -0.445720    -0.380980 -0.383024     0.502618  \n",
       "2        5.315688  1.425623     1.929654  3.039265     2.444876  \n",
       "3        0.250161 -0.167058     0.402586 -0.265849    -0.449312  \n",
       "4       -0.354131 -0.497826    -0.629813 -0.942688    -0.125699  \n",
       "...           ...       ...          ...       ...          ...  \n",
       "2733388  0.303709  1.265191     1.891532  5.087656     2.890119  \n",
       "2733389 -0.379467 -0.003251    -0.058665  0.069646    -1.801336  \n",
       "2733390 -0.406718 -0.253716    -0.259289 -0.266124    -2.689775  \n",
       "2733391 -0.430935 -0.279941    -0.377621  0.131903    -1.265594  \n",
       "2733392 -0.395777  0.318454     0.397276 -1.152539    -3.110605  \n",
       "\n",
       "[2733393 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 36\n",
    "def split(data_array, ret_array):\n",
    "    num_rows = data_array.shape[0]\n",
    "    if num_rows >= window + 4:  \n",
    "        windowed_data = sliding_window_view(data_array, window_shape=(window, data_array.shape[1]))\n",
    "        targets = ret_array[window + 3:num_rows]  \n",
    "        return windowed_data[:len(targets)], targets  \n",
    "    return np.empty((0, window, data_array.shape[1])), np.array([])\n",
    "\n",
    "data_array = standardized_df[standardized_df['symbol'] == '300793'][columns].values\n",
    "ret_array = standardized_df[standardized_df['symbol'] == '300793']['ret_predict'].values\n",
    "result, y_values = split(data_array, ret_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Dataframe to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {symbol: group for symbol, group in standardized_df.groupby('symbol')}\n",
    "columns = filtered_df.columns.difference(['date', 'symbol', 'ret_predict'])\n",
    "time_series = []\n",
    "targets = []\n",
    "symbols = []\n",
    "def split(data_array, ret_array):\n",
    "    num_rows = data_array.shape[0]\n",
    "    if num_rows >= window + 4:  \n",
    "        windowed_data = sliding_window_view(data_array, window_shape=(window, data_array.shape[1]))\n",
    "        targets = ret_array[window + 3:num_rows]  \n",
    "        return windowed_data[:len(targets)], targets  \n",
    "    return np.empty((0, window, data_array.shape[1])), np.array([])\n",
    "\n",
    "for symbol, group_data in groups.items():\n",
    "    data_array = group_data[columns].values\n",
    "    ret_array = group_data['ret_predict'].values\n",
    "    result, y_values = split(data_array, ret_array)\n",
    "    if result.size > 0:\n",
    "        time_series.append(result)\n",
    "        targets.append(y_values)\n",
    "        symbols.append(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {symbol: group for symbol, group in standardized_df.groupby('symbol')}\n",
    "columns = filtered_df.columns.difference(['date', 'symbol', 'ret_predict'])\n",
    "time_series = []\n",
    "targets = []\n",
    "symbols = []\n",
    "dates = []\n",
    "\n",
    "def split(data_array, ret_array, date, window):\n",
    "    num_rows = data_array.shape[0]\n",
    "    if num_rows >= window + 4:  \n",
    "        windowed_data = sliding_window_view(data_array, window_shape=(window, data_array.shape[1]))\n",
    "        targets = ret_array[window + 3:num_rows]  \n",
    "        date_array = date[window + 3:num_rows]\n",
    "        return windowed_data[:len(targets)], targets, date_array\n",
    "    return np.empty((0, window, data_array.shape[1])), np.array([]), np.array([])\n",
    "\n",
    "for symbol, group_data in groups.items():\n",
    "    data_array = group_data[columns].values\n",
    "    ret_array = group_data['ret_predict'].values\n",
    "    date = group_data['date'].values\n",
    "    result, y_values, date_values = split(data_array, ret_array, date, window)\n",
    "    if result.size > 0:\n",
    "        time_series.append(result)\n",
    "        targets.append(y_values)\n",
    "        dates.append(date_values)\n",
    "        repeated_symbols = np.repeat(symbol, date_values.shape[0])\n",
    "        symbols.append(repeated_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_date = np.concatenate(dates)\n",
    "flattened_symbol = np.concatenate(symbols)\n",
    "df = pd.DataFrame({\n",
    "    'date': flattened_date,\n",
    "    'symbol': flattened_symbol\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('factor/model_2.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 540723 entries, 0 to 540722\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype         \n",
      "---  ------   --------------   -----         \n",
      " 0   date     540723 non-null  datetime64[ns]\n",
      " 1   symbol   540723 non-null  object        \n",
      " 2   model_2  540723 non-null  float32       \n",
      "dtypes: datetime64[ns](1), float32(1), object(1)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>model_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>000001</td>\n",
       "      <td>-0.081515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>000001</td>\n",
       "      <td>-0.083043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>000001</td>\n",
       "      <td>-0.085016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>000001</td>\n",
       "      <td>-0.078198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>000001</td>\n",
       "      <td>-0.080063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540718</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>688981</td>\n",
       "      <td>-0.096773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540719</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>688981</td>\n",
       "      <td>-0.079881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540720</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>688981</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540721</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>688981</td>\n",
       "      <td>-0.029280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540722</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>688981</td>\n",
       "      <td>-0.082821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540723 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  symbol   model_2\n",
       "0      2020-04-13  000001 -0.081515\n",
       "1      2020-04-14  000001 -0.083043\n",
       "2      2020-04-15  000001 -0.085016\n",
       "3      2020-04-16  000001 -0.078198\n",
       "4      2020-04-17  000001 -0.080063\n",
       "...           ...     ...       ...\n",
       "540718 2020-12-25  688981 -0.096773\n",
       "540719 2020-12-28  688981 -0.079881\n",
       "540720 2020-12-29  688981  0.017141\n",
       "540721 2020-12-30  688981 -0.029280\n",
       "540722 2020-12-31  688981 -0.082821\n",
       "\n",
       "[540723 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import LSTM\n",
    "model_name = \"models/prediction_size_3_window_20_hidden_dim_64_num_layers_2_val.pth\"\n",
    "device = \"cuda:0\"\n",
    "input_size = 18\n",
    "prediction_size = 3\n",
    "window = 20\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "model = LSTM(input_size, hidden_dim, num_layers, output_dim).to(device)\n",
    "checkpoint = torch.load(model_name, map_location = device)\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0',\n",
       "              tensor([[-0.0696, -0.0150, -0.0171,  ...,  0.0368,  0.0394, -0.0042],\n",
       "                      [-0.0509,  0.1333, -0.0640,  ...,  0.0397,  0.1136,  0.0124],\n",
       "                      [-0.1237, -0.1099, -0.0788,  ..., -0.0565,  0.0051,  0.1293],\n",
       "                      ...,\n",
       "                      [-0.0381, -0.1057, -0.0089,  ..., -0.0470, -0.1087,  0.1119],\n",
       "                      [-0.0776, -0.0794, -0.0083,  ...,  0.0022,  0.1073,  0.0547],\n",
       "                      [ 0.1140, -0.0380, -0.0204,  ..., -0.1152,  0.1054,  0.0529]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-4.7108e-02,  1.3702e-02,  3.4357e-04,  ...,  1.6176e-02,\n",
       "                       -3.1728e-02, -7.1582e-03],\n",
       "                      [-1.1653e-02,  9.9252e-02,  2.2549e-03,  ..., -8.6145e-03,\n",
       "                        3.2503e-02, -5.7776e-02],\n",
       "                      [-2.9908e-02,  2.7432e-02, -3.3559e-02,  ...,  4.3710e-03,\n",
       "                        4.7851e-02, -1.9618e-02],\n",
       "                      ...,\n",
       "                      [-6.3956e-03, -5.1112e-03,  6.7475e-02,  ..., -2.0997e-01,\n",
       "                       -5.8627e-02,  1.4156e-01],\n",
       "                      [-1.5045e-01,  1.2368e-01, -2.6296e-01,  ...,  6.9760e-02,\n",
       "                        3.2150e-01, -1.9551e-02],\n",
       "                      [ 5.9287e-02, -1.0322e-01, -2.0524e-01,  ..., -6.2980e-02,\n",
       "                       -4.1285e-02, -5.0081e-01]], device='cuda:0')),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([-7.9943e-02,  4.9233e-02, -1.0001e-02,  1.0513e-01,  5.7063e-02,\n",
       "                      -2.7535e-02, -1.1696e-01, -1.1264e-01,  6.4458e-02,  4.4920e-02,\n",
       "                       9.8236e-02,  3.8667e-02,  1.2279e-01, -1.6671e-02, -1.0206e-01,\n",
       "                       9.1569e-02,  1.3164e-01,  3.3999e-02,  1.7051e-01,  2.4037e-01,\n",
       "                      -7.8432e-02, -7.6286e-02,  1.6003e-02, -7.1740e-03,  2.3693e-01,\n",
       "                      -8.3646e-02,  1.9762e-02,  3.1598e-01,  1.3326e-01,  1.6329e-01,\n",
       "                      -3.1942e-02, -8.5329e-02, -1.1474e-01, -1.3071e-02,  2.9413e-02,\n",
       "                       5.3403e-02, -8.0647e-03,  3.4682e-02,  2.7301e-02, -8.6198e-02,\n",
       "                       2.0006e-01, -1.0206e-01,  1.9564e-01,  2.1769e-01,  1.6767e-01,\n",
       "                       2.7258e-04,  3.8998e-02,  2.0594e-01,  2.4208e-02,  3.5537e-02,\n",
       "                      -1.3728e-01,  1.0528e-01,  1.2135e-01, -1.5810e-01, -1.4829e-01,\n",
       "                      -6.3349e-02,  8.3603e-02,  2.3502e-02,  2.9843e-03, -6.4905e-02,\n",
       "                       4.9505e-02, -1.4988e-01,  3.0182e-01,  4.7499e-02,  3.2635e-01,\n",
       "                      -1.1027e-01,  2.8145e-01,  5.6798e-02,  2.0794e-01,  3.7389e-01,\n",
       "                       3.9120e-01,  5.7746e-02,  3.8369e-01,  4.3633e-01,  1.4030e-01,\n",
       "                       1.9188e-01,  1.3618e-01,  3.0287e-01,  1.5136e-01,  3.6253e-01,\n",
       "                       1.7305e-01,  2.6973e-01,  3.1347e-01,  2.5382e-01,  4.2515e-01,\n",
       "                       2.9665e-01,  1.3281e-01,  4.4833e-01, -3.5984e-01,  2.8740e-01,\n",
       "                       1.6853e-01,  1.2316e-01,  4.7172e-01,  3.5293e-01,  4.6521e-01,\n",
       "                       4.4982e-02,  4.5751e-01,  2.8984e-02,  1.6440e-01,  1.7921e-01,\n",
       "                       1.0834e-01,  2.5349e-01,  3.5453e-01,  2.6352e-01, -8.2039e-02,\n",
       "                       3.1483e-01,  2.2471e-01,  1.0410e-01,  2.1927e-01,  3.4184e-01,\n",
       "                       1.3667e-01,  9.4221e-02,  3.6517e-01,  2.4750e-01,  2.9479e-01,\n",
       "                       1.4729e-01,  2.8973e-01,  1.2462e-02,  3.7713e-01,  3.0547e-01,\n",
       "                       5.2982e-01,  3.2036e-01,  3.9900e-01,  9.0999e-02,  2.7847e-01,\n",
       "                       4.8986e-01,  2.8088e-01,  2.8346e-01, -5.8368e-02,  2.5774e-02,\n",
       "                      -1.7400e-01,  2.0858e-01, -4.7549e-02, -2.6285e-01,  6.5899e-02,\n",
       "                       2.7786e-02, -3.8731e-02, -4.3566e-02,  2.9463e-01,  8.8988e-02,\n",
       "                      -3.7756e-01,  1.6178e-01,  2.6120e-01, -4.0422e-01,  7.5329e-02,\n",
       "                       2.3670e-01, -3.3265e-01,  2.7658e-01,  1.6930e-01,  2.9895e-01,\n",
       "                      -6.1024e-02, -3.8697e-01, -2.8959e-01,  1.4304e-01, -2.9386e-02,\n",
       "                       2.1134e-01,  4.9574e-01,  4.2401e-01, -1.4074e-01,  7.7032e-02,\n",
       "                       1.6835e-01,  3.8761e-01,  1.6213e-01, -6.6383e-02,  2.9433e-01,\n",
       "                      -2.2039e-01,  1.3236e-01,  1.2856e-01,  3.7472e-02,  1.1614e-01,\n",
       "                      -4.4252e-02,  5.9206e-02, -1.0499e-01, -1.4204e-01, -9.3411e-02,\n",
       "                      -6.5972e-02,  5.2283e-02,  2.1014e-01, -2.0254e-02,  5.8929e-02,\n",
       "                      -2.8586e-01,  3.1612e-02,  6.8897e-03,  3.6494e-02, -2.4231e-01,\n",
       "                      -3.9132e-01,  1.4909e-01, -2.1013e-01, -6.7865e-02,  4.2571e-02,\n",
       "                       5.2843e-01, -1.6762e-01], device='cuda:0')),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-5.3322e-02,  5.1075e-02,  2.6424e-02,  4.6859e-02,  3.9626e-02,\n",
       "                      -2.4043e-02, -4.7726e-02, -1.0600e-01,  4.8492e-02,  4.8948e-02,\n",
       "                       1.3043e-01,  4.3464e-02,  1.6673e-01,  7.9890e-03, -6.6969e-02,\n",
       "                       1.0569e-01,  1.3195e-01, -6.7760e-02,  1.5404e-01,  2.6764e-01,\n",
       "                      -7.7136e-02, -3.4557e-02,  6.2738e-02, -1.9852e-02,  2.7249e-01,\n",
       "                      -1.0621e-01,  4.4178e-02,  2.4921e-01,  1.0466e-01,  3.2713e-01,\n",
       "                      -6.3362e-02, -1.1521e-01, -1.2945e-01,  7.6672e-02,  3.7853e-02,\n",
       "                       2.7728e-02, -3.0872e-02,  3.2996e-02,  6.2549e-02, -9.5737e-02,\n",
       "                       2.4874e-01, -1.1645e-01,  2.0143e-01,  2.3552e-01,  2.1919e-01,\n",
       "                       1.2119e-02,  2.2590e-02,  1.2987e-01,  2.6917e-02,  4.6140e-02,\n",
       "                      -1.4670e-01,  1.1248e-01,  1.1396e-01, -1.2229e-01, -1.4303e-01,\n",
       "                      -5.9576e-02,  1.5892e-02,  5.1292e-02, -1.6187e-02, -2.5495e-02,\n",
       "                       1.2446e-02, -1.7789e-01,  2.6959e-01,  3.6068e-02,  3.6786e-01,\n",
       "                      -1.7383e-01,  2.4420e-01,  4.8169e-02,  2.8874e-01,  2.4849e-01,\n",
       "                       4.3772e-01,  8.3559e-02,  3.6409e-01,  3.0725e-01,  2.8647e-01,\n",
       "                       1.6435e-01,  4.8640e-02,  1.9969e-01,  1.4389e-01,  3.4485e-01,\n",
       "                       1.9222e-01,  3.2625e-01,  3.9608e-01,  2.3488e-01,  3.7935e-01,\n",
       "                       4.0215e-01,  1.6627e-01,  4.8957e-01, -4.0757e-01,  2.5204e-01,\n",
       "                       2.4925e-01,  1.0985e-01,  4.7974e-01,  3.0491e-01,  4.2207e-01,\n",
       "                      -1.0451e-02,  4.1561e-01, -9.0241e-02,  2.9463e-01,  1.8020e-01,\n",
       "                       8.4682e-02,  2.9401e-01,  3.2476e-01,  3.4567e-01, -5.9328e-02,\n",
       "                       3.2815e-01,  2.9494e-01,  1.9731e-01,  2.1457e-01,  2.5999e-01,\n",
       "                       3.2948e-02,  6.1196e-02,  3.6409e-01,  2.6413e-01,  3.9341e-01,\n",
       "                       2.2834e-01,  1.6082e-01,  1.4828e-02,  4.6551e-01,  2.6158e-01,\n",
       "                       4.6065e-01,  2.3186e-01,  3.9309e-01,  1.3422e-01,  3.0270e-01,\n",
       "                       5.6368e-01,  3.6304e-01,  2.4033e-01, -2.1475e-02, -4.4837e-02,\n",
       "                      -1.4100e-01,  1.6438e-01,  4.7600e-02, -1.5706e-01,  2.3997e-03,\n",
       "                      -1.6010e-01, -2.2624e-02, -1.4381e-01, -5.0186e-03, -2.6643e-02,\n",
       "                      -3.0333e-01,  8.8764e-02,  1.2906e-01, -2.1480e-01,  1.6251e-01,\n",
       "                       2.4669e-01, -4.7472e-01,  1.9635e-01,  4.1117e-02,  2.3231e-01,\n",
       "                      -2.4561e-02, -2.0427e-01, -3.8360e-01,  3.6641e-02,  2.0057e-02,\n",
       "                       1.9394e-01,  3.2309e-01,  5.1916e-01, -2.3183e-01,  3.4267e-02,\n",
       "                       1.6374e-01, -2.2892e-01,  8.9739e-02, -2.0211e-02,  3.0190e-01,\n",
       "                      -3.2623e-04,  8.8703e-02,  8.4081e-02,  2.0736e-01, -2.1061e-02,\n",
       "                      -2.0882e-01, -1.8930e-02, -1.8486e-01, -9.0462e-02,  2.5623e-01,\n",
       "                      -2.8412e-02, -1.4162e-01,  1.1266e-01,  4.1811e-03,  6.0213e-02,\n",
       "                      -2.7070e-01, -2.1053e-02, -6.6005e-02, -8.8747e-02, -4.0866e-01,\n",
       "                      -2.0211e-01,  4.0707e-02,  1.0718e-01, -1.0463e-01,  1.1802e-01,\n",
       "                       5.8278e-01, -1.8381e-01], device='cuda:0')),\n",
       "             ('lstm.weight_ih_l1',\n",
       "              tensor([[-0.0103, -0.0379, -0.0294,  ...,  0.0185,  0.0388,  0.0219],\n",
       "                      [ 0.0290, -0.0363, -0.0267,  ...,  0.0300,  0.0950, -0.0105],\n",
       "                      [-0.0089, -0.0200, -0.0053,  ...,  0.0718,  0.0455, -0.0007],\n",
       "                      ...,\n",
       "                      [ 0.0019,  0.1283, -0.0712,  ...,  0.1041,  0.0982, -0.0094],\n",
       "                      [-0.0192,  0.0280,  0.0020,  ...,  0.0820,  0.1572, -0.0438],\n",
       "                      [-0.0204, -0.1868,  0.0092,  ..., -0.0905, -0.0217, -0.0276]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l1',\n",
       "              tensor([[ 9.4178e-02,  1.3125e-03, -4.4003e-02,  ...,  4.3071e-02,\n",
       "                        6.9210e-02, -5.2647e-02],\n",
       "                      [-4.8735e-02, -5.3147e-02,  3.3064e-02,  ..., -1.4777e-02,\n",
       "                       -3.6954e-02,  1.5519e-02],\n",
       "                      [ 9.2383e-03,  5.8657e-02, -1.4457e-05,  ...,  3.8806e-02,\n",
       "                        3.8276e-02,  1.4807e-02],\n",
       "                      ...,\n",
       "                      [-1.5219e-01, -5.6453e-02,  1.8495e-01,  ..., -3.2705e-01,\n",
       "                       -1.7979e-01,  1.7119e-01],\n",
       "                      [-1.7726e-01,  1.2863e-01,  8.5471e-02,  ..., -1.1609e-01,\n",
       "                       -2.8645e-01,  1.1154e-01],\n",
       "                      [ 2.5357e-02,  1.3947e-02,  1.0019e-02,  ..., -2.2647e-02,\n",
       "                        5.0757e-02,  9.0505e-03]], device='cuda:0')),\n",
       "             ('lstm.bias_ih_l1',\n",
       "              tensor([ 0.0093,  0.1432,  0.0298,  0.3143,  0.1750,  0.1210, -0.0313,  0.0087,\n",
       "                       0.1013,  0.0224, -0.0229, -0.0364,  0.1585,  0.1248,  0.2688,  0.1092,\n",
       "                      -0.0742,  0.0628,  0.3158, -0.0470, -0.1163,  0.1912,  0.0924, -0.0951,\n",
       "                       0.0372,  0.0704, -0.0483,  0.0280, -0.0668, -0.0742,  0.1043, -0.0801,\n",
       "                       0.2117,  0.1791, -0.0656,  0.2350,  0.0771, -0.0097, -0.0102, -0.0968,\n",
       "                       0.0111,  0.2568, -0.0625,  0.0665,  0.2300,  0.1219,  0.1205,  0.0627,\n",
       "                       0.3235,  0.0804,  0.0240, -0.0583, -0.0327,  0.0927,  0.0194,  0.2423,\n",
       "                       0.1173, -0.0314,  0.0069,  0.2999, -0.0804,  0.0957,  0.0612, -0.1127,\n",
       "                       0.2381, -0.1404,  0.3963,  0.0038,  0.1932,  0.0044,  0.2174, -0.0324,\n",
       "                      -0.0154,  0.2774, -0.0326,  0.1489,  0.4367,  0.1069, -0.1223,  0.1430,\n",
       "                       0.2329,  0.3592,  0.1652,  0.5143,  0.2491,  0.0226,  0.0814,  0.2583,\n",
       "                       0.0150,  0.3121,  0.4224,  0.3111,  0.2843,  0.1250,  0.0921,  0.3242,\n",
       "                       0.1562,  0.0834,  0.2851, -0.1540, -0.0293,  0.3180,  0.3289,  0.2337,\n",
       "                       0.2866,  0.1650,  0.4010,  0.2928, -0.0252, -0.0716,  0.2675,  0.0442,\n",
       "                       0.0372,  0.5319,  0.3967,  0.3729,  0.2549, -0.0254,  0.1371, -0.3502,\n",
       "                       0.3135,  0.3230, -0.0101, -0.0582,  0.1939,  0.2293,  0.0663,  0.5601,\n",
       "                      -0.0742, -0.1290,  0.1555, -0.0126,  0.0355, -0.0816, -0.0785,  0.0020,\n",
       "                       0.0595, -0.1660,  0.1263, -0.1357,  0.1483,  0.0139,  0.0666, -0.0541,\n",
       "                       0.1335, -0.1467,  0.0525, -0.1696,  0.0295, -0.0876,  0.0307,  0.1838,\n",
       "                       0.0581,  0.0091, -0.0854,  0.0800, -0.2187, -0.0835, -0.0666,  0.2329,\n",
       "                      -0.0180, -0.0654,  0.1279,  0.0873, -0.0414,  0.0762,  0.0858, -0.1149,\n",
       "                       0.1352,  0.0918,  0.2171, -0.0264, -0.0455,  0.0847,  0.0316, -0.0095,\n",
       "                      -0.0115,  0.0562, -0.0856, -0.2208,  0.0851,  0.0489, -0.0922, -0.0675,\n",
       "                      -0.0267, -0.0548, -0.0740,  0.0460, -0.1972,  0.0272, -0.0264,  0.0908],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l1',\n",
       "              tensor([ 0.0206,  0.1665,  0.0338,  0.3423,  0.3127,  0.0164, -0.0226,  0.1254,\n",
       "                       0.0802, -0.0410, -0.0207, -0.0892,  0.1960,  0.2187,  0.1610, -0.0312,\n",
       "                      -0.0659, -0.0461,  0.3102, -0.0490, -0.1042,  0.3020,  0.1488, -0.0789,\n",
       "                       0.0663,  0.0408, -0.0333,  0.1394, -0.0713, -0.0755,  0.1147, -0.0803,\n",
       "                       0.1395,  0.1903, -0.0761,  0.2535,  0.0953, -0.0593,  0.0286, -0.0927,\n",
       "                       0.0102,  0.1411, -0.0422,  0.0637,  0.1397,  0.1163,  0.1891,  0.1008,\n",
       "                       0.2131,  0.0768,  0.0116, -0.0583,  0.0273,  0.2132, -0.0032,  0.2867,\n",
       "                       0.1274, -0.0320,  0.0777,  0.3074, -0.0949,  0.0917,  0.0087, -0.1129,\n",
       "                       0.3632, -0.1081,  0.3858, -0.0292,  0.0495,  0.1031,  0.1364,  0.0608,\n",
       "                      -0.0165,  0.2190,  0.0137,  0.0928,  0.4522,  0.0736, -0.1245,  0.1128,\n",
       "                       0.3160,  0.3883,  0.0885,  0.4873,  0.3229, -0.1041,  0.1098,  0.2704,\n",
       "                       0.0561,  0.1867,  0.2615,  0.2293,  0.2496,  0.1332, -0.0140,  0.3820,\n",
       "                       0.1350,  0.0790,  0.3670, -0.0831, -0.0405,  0.2551,  0.2566,  0.1780,\n",
       "                       0.3115,  0.2616,  0.3577,  0.3576, -0.0906, -0.0590,  0.3043,  0.1135,\n",
       "                      -0.1146,  0.5062,  0.4403,  0.3505,  0.2658,  0.1006,  0.2205, -0.3390,\n",
       "                       0.3942,  0.3175, -0.0275,  0.0273,  0.1963,  0.1345,  0.1729,  0.5958,\n",
       "                      -0.1900, -0.0016,  0.1523,  0.0313, -0.0596, -0.0277, -0.1056, -0.0941,\n",
       "                       0.0664, -0.0534,  0.2272, -0.1632, -0.0581,  0.1177,  0.0011, -0.0738,\n",
       "                       0.0424, -0.0026, -0.0357, -0.1820,  0.1054,  0.0111, -0.0170,  0.1213,\n",
       "                       0.0151,  0.1538, -0.0830,  0.0532, -0.0487, -0.1436, -0.1147,  0.0842,\n",
       "                      -0.0441, -0.0816,  0.1374, -0.0060, -0.0036,  0.0419,  0.1799, -0.0932,\n",
       "                       0.0609, -0.0417,  0.2517, -0.0377, -0.0433,  0.0092, -0.0960, -0.0443,\n",
       "                       0.1231, -0.0461, -0.1206, -0.0661,  0.0922, -0.0481,  0.0090,  0.0425,\n",
       "                      -0.1285, -0.1794, -0.1066, -0.0301, -0.0570, -0.0443, -0.1685,  0.0386],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.weight',\n",
       "              tensor([[ 0.4075,  0.1544, -0.3758, -0.4811,  0.2313,  0.2690,  0.3678,  0.3879,\n",
       "                       -0.0447,  0.4553, -0.3274,  0.3618, -0.4051, -0.3882, -0.2153,  0.3594,\n",
       "                       -0.3661,  0.4177, -0.0735,  0.3841, -0.3404,  0.4278,  0.2892, -0.3593,\n",
       "                       -0.2177, -0.3551,  0.3411, -0.3475,  0.2987,  0.3667,  0.4474, -0.4227,\n",
       "                        0.3119,  0.4399, -0.3833, -0.1499, -0.0319, -0.3470, -0.3274,  0.2150,\n",
       "                       -0.3988,  0.5167, -0.3733,  0.3639, -0.2801, -0.0341,  0.4250, -0.0744,\n",
       "                        0.3994, -0.3266,  0.4228,  0.3502, -0.4306, -0.3381,  0.3382,  0.2696,\n",
       "                        0.3952,  0.3216,  0.4361,  0.2480,  0.4213,  0.3143,  0.4177, -0.3198]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.bias', tensor([-0.0684], device='cuda:0'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data_array, ret_array, date, window):\n",
    "    num_rows = data_array.shape[0]\n",
    "    if num_rows >= window + 4:  \n",
    "        windowed_data = sliding_window_view(data_array, window_shape=(window, data_array.shape[1]))\n",
    "        targets = ret_array[window + 3:num_rows]  \n",
    "        date_array = date[window + 3:num_rows]\n",
    "        return windowed_data[:len(targets)], targets, date_array\n",
    "    return np.empty((0, window, data_array.shape[1])), np.array([]), np.array([])\n",
    "\n",
    "def standardize_and_split(df, prediction_size, pools_df, window):\n",
    "    df['ret_predict'] = df.groupby('symbol')['ret'].transform(\n",
    "        lambda x: x.rolling(window=prediction_size).apply(lambda y: (y + 1).prod(), raw=True) - 1\n",
    "    )\n",
    "    df = df.dropna()\n",
    "    filtered_df = pd.merge(df, pools_df, on=['date', 'symbol'], how='inner')\n",
    "\n",
    "    columns = filtered_df.columns.difference(['date', 'symbol'])\n",
    "    standardized_df = filtered_df.copy()  \n",
    "    standardized_df[columns] = (\n",
    "        filtered_df[columns]\n",
    "        .groupby(filtered_df['date'])\n",
    "        .transform(lambda x: (x - x.mean()) / x.std())\n",
    "    )\n",
    "\n",
    "    groups = {symbol: group for symbol, group in standardized_df.groupby('symbol')}\n",
    "    columns = filtered_df.columns.difference(['date', 'symbol', 'ret_predict'])\n",
    "    time_series = []\n",
    "    targets = []\n",
    "    symbols = []\n",
    "    dates = []\n",
    "    for symbol, group_data in groups.items():\n",
    "        data_array = group_data[columns].values\n",
    "        ret_array = group_data['ret_predict'].values\n",
    "        date = group_data['date'].values\n",
    "        result, y_values, date_values = split(data_array, ret_array, date, window)\n",
    "        if result.size > 0:\n",
    "            time_series.append(result)\n",
    "            targets.append(y_values)\n",
    "            dates.append(date_values)\n",
    "            repeated_symbols = np.repeat(symbol, date_values.shape[0])\n",
    "            symbols.append(repeated_symbols)\n",
    "\n",
    "    data_list = [np.squeeze(np.array(arr),axis=1) for arr in time_series]  \n",
    "    stacked_data = np.vstack(data_list)  \n",
    "    X = torch.tensor(stacked_data, dtype=torch.float32)\n",
    "\n",
    "    stacked_targets = np.concatenate(targets)\n",
    "    y = torch.tensor(stacked_targets, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X , y , dates , symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): GRU(9, 512, num_layers=5, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_begin_date = '2020-01-03'\n",
    "test_end_date = '2020-12-31'\n",
    "threshold_of_grow_and_decline = 0.5\n",
    "prediction_size = 3\n",
    "window = 36\n",
    "input_size = 9\n",
    "hidden_dim = 512\n",
    "num_layers = 5\n",
    "output_dim = 1\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "status = fds.list_status(test_begin_date, test_end_date, columns=None)\n",
    "bars = fds.bar(test_begin_date, test_end_date, freq='1d')\n",
    "# 剔除 涨跌停超过一定值 PT ST 股票池\n",
    "\n",
    "flager = fds.bar(test_begin_date, test_end_date, freq='5m')\n",
    "flager['close_ge_high'] = (flager['close'] >= flager['high']).astype(int)\n",
    "flager['close_le_low'] = (flager['close'] <= flager['low']).astype(int)\n",
    "flags_high_ratio = flager.groupby(['date', 'symbol'])['close_ge_high'].transform('mean')\n",
    "flags_low_ratio = flager.groupby(['date', 'symbol'])['close_le_low'].transform('mean')\n",
    "flager['flag'] = ((flags_high_ratio > threshold_of_grow_and_decline) | (flags_low_ratio > threshold_of_grow_and_decline)).astype(int)\n",
    "daily_flags = (flager.groupby(['date', 'symbol'])['flag']\n",
    "            .first()\n",
    "            .reset_index())\n",
    "pools = {}\n",
    "merged = pd.merge(bars, status, on=['date', 'symbol'], how='left')\n",
    "merged = pd.merge(merged, daily_flags, on=['date', 'symbol'], how='left')\n",
    "\n",
    "filtered = merged[(merged['PT'] != 1) & (merged['ST'] != 1) & (merged['turnover'] != 0) & (merged['flag'] != 1)]\n",
    "pools = {date: symbols.reset_index(drop=True) for date, symbols in filtered.groupby('date')['symbol']}\n",
    "pools_df = pd.concat(pools.values(), keys=pools.keys()).reset_index().drop('level_1', axis=1)\n",
    "pools_df.columns = ['date', 'symbol']\n",
    "\n",
    "# 添加预测日收益率 标准化 数据集拆分\n",
    "df = bars\n",
    "df['ret'] = df['close']/df['pre_close'] - 1\n",
    "test_X , test_y , dates , symbols = standardize_and_split(df, prediction_size, pools_df, window)\n",
    "\n",
    "flattened_date = np.concatenate(dates)\n",
    "flattened_symbol = np.concatenate(symbols)\n",
    "df = pd.DataFrame({\n",
    "    'date': flattened_date,\n",
    "    'symbol': flattened_symbol\n",
    "})\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=False, pin_memory=True)\n",
    "\n",
    "model = LSTM(input_size, hidden_dim, num_layers, output_dim).to(device)\n",
    "\n",
    "model_dir=\"models/all_states_hidden512.pth\"\n",
    "checkpoint = torch.load(model_dir)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): GRU(9, 128, num_layers=3, batch_first=True)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 9\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "output_dim = 1\n",
    "model = LSTM(input_size, hidden_dim, num_layers, output_dim).to(device)\n",
    "\n",
    "model_dir=\"models/all_states.pth\"\n",
    "checkpoint = torch.load(model_dir)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = []\n",
    "    for batch_idx, (data, target) in enumerate(test_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs.append(model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [np.squeeze(np.array(arr),axis=1) for arr in time_series]  \n",
    "stacked_data = np.vstack(data_list)  \n",
    "X = torch.tensor(stacked_data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2587391, 36, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_targets = np.concatenate(targets)\n",
    "y = torch.tensor(stacked_targets, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2587391, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.GRU(input_size, hidden_dim, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        output = output[:,-1,:]\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, logger, device):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        train_loss.append(loss.item())\n",
    "        if batch_idx % 100 == 0:\n",
    "            logger.info('Train Loss: {:.10f}, Batch Index: [{}]/[{}]'.format(loss.item(), batch_idx, len(dataloader)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss\n",
    "\n",
    "def test(model, dataloader, optimizer, criterion, logger, device):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            test_loss.append(loss.item())\n",
    "            if batch_idx % 100 == 0:\n",
    "                logger.info('Test Loss: {:.10f}, Batch Index: [{}]/[{}]'.format(loss.item(), batch_idx, len(dataloader)))\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def main(test_flag=False, model_dir=\"models/all_states.pth\"):\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    filename='training.log', filemode='w')\n",
    "    logger = logging.getLogger()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    input_size = 9\n",
    "    hidden_dim = 128\n",
    "    num_layers = 3\n",
    "    output_dim = 1\n",
    "    epochs = 200\n",
    "    dataset = TensorDataset(X, y)\n",
    "    batch_size = 64  \n",
    "    shuffle_dataset = True  \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_dataset, pin_memory=True)\n",
    "    \n",
    "    model = LSTM(input_size, hidden_dim, num_layers, output_dim).to(device)\n",
    "    criterion = torch.nn.MSELoss(reduction='mean').to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    min_loss = np.Inf\n",
    "    \n",
    "    if test_flag:\n",
    "        logger.info('Testing mode')\n",
    "        checkpoint = torch.load(model_dir)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        test(model, dataloader, optimizer, criterion, logger, device)\n",
    "        return\n",
    "\n",
    "    if os.path.exists(model_dir):\n",
    "        checkpoint = torch.load(model_dir)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        logger.info('Loaded model from epoch {}'.format(start_epoch))\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        logger.info('No saved model found, starting training from scratch')\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        train_loss = train(model, dataloader, optimizer, criterion, logger, device)\n",
    "        if np.mean(train_loss) < min_loss:\n",
    "            # 保存模型\n",
    "            state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n",
    "            torch.save(state, model_dir)\n",
    "            logger.info('Model saved successfully!')\n",
    "        # test(model, dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(test_flag=False, model_dir=\"models/all_states.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Extracting epochs and losses for plotting\u001b[39;00m\n\u001b[1;32m     25\u001b[0m train_epochs, train_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mepoch_train_losses)\n\u001b[0;32m---> 26\u001b[0m val_epochs, val_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mepoch_val_losses)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Creating the plot\u001b[39;00m\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "log_file_path = '/root/gru/log/input_size_18_prediction_size_6_window_51_hidden_dim_448_num_layers_4.log'\n",
    "\n",
    "# Lists to hold extracted data\n",
    "epoch_train_losses = []\n",
    "epoch_val_losses = []\n",
    "\n",
    "# Regular expressions to find epoch summary train and validation losses\n",
    "train_pattern = re.compile(r'Epoch: (\\d+), train loss: ([0-9.]+), train min loss: ([0-9.]+)')\n",
    "val_pattern = re.compile(r'Epoch: (\\d+), val loss: ([0-9.]+), valid min loss: ([0-9.]+)')\n",
    "\n",
    "# Reading and extracting data from the log file\n",
    "with open(log_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        train_match = train_pattern.search(line)\n",
    "        if train_match:\n",
    "            epoch, loss, min_loss = train_match.groups()\n",
    "            epoch_train_losses.append((int(epoch), float(loss)))\n",
    "        \n",
    "        val_match = val_pattern.search(line)\n",
    "        if val_match:\n",
    "            epoch, loss, min_loss = val_match.groups()\n",
    "            epoch_val_losses.append((int(epoch), float(loss)))\n",
    "\n",
    "# Extracting epochs and losses for plotting\n",
    "train_epochs, train_losses = zip(*epoch_train_losses)\n",
    "val_epochs, val_losses = zip(*epoch_val_losses)\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_epochs, train_losses, label='Epoch Train Loss', marker='o')\n",
    "plt.plot(val_epochs, val_losses, label='Epoch Validation Loss', marker='x')\n",
    "plt.title('Epoch Summary: Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Adjust x-axis to show every five epochs\n",
    "max_epoch = max(max(train_epochs), max(val_epochs))\n",
    "plt.xticks(range(0, max_epoch + 1, 5))  # Adjust as necessary based on the number of epochs\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
